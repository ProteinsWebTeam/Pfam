Genome annotations overview:

********************************
**CAVEATS***-all in the input output locations should be checked in the code before running as all the Rfam dir locations are currently in the middle of being changed....
********************************

(1)make empty db (e.g rfam_10_0) on dev and copy over data from rfamlive

(2)Get the list of completed genomes from the EBI and assign where to get them from (rfamseq or con file)

(2a) Doctor the list of accessions to include the accessions we want to use ? -see section on ENSEMBL

(3)Use the assigned list from 2 to generate the agp files for the con and Rfamseq genomes - (deal with ENSEMBL)

(4)Load the agp data into the rdb 

(5)make the gff files

(6)make the sscons files

(7)make the genome_summary data

************
code used
./parse_ann_con.pl
./assign_genomes.pl
./make_genome_agp.pl
./load_genome_entry.pl 
./makeGFF3.pl 
./makeFastaSS.pl
./load_genome_summary.pl 

ensembl-not used
./getENSdb.pl
./getCoordSystem.pl
./runAssemblyMap.sh 
./assembly_mapping.pl 
./change_genomes_GRCh37.pl 

************

***************
IN:Use the CON_ANN files that come with the EMBL release (nb. ANN files will be deprecated after EMBL release 100)

OUT : write out .agp and log files and data to:/nfs/pfam_nfs/rfam/rfamseq/10/Genomes_10.0
this is set up by the first bit of code we run

GENERATE IDLIST from the CON_ANN files:
grep -H ^ID rel*dat > IDlist;

REDUCE CON_ANN to minimal data: do this for the ann and con files then gzip up the full files
 
foreach f ( `ls | grep ann` )
perl /lustre/pfam/rfam/Users/jd7/Rfam_builds/RELEASE_10.0/mkrelease/parse_ann_con.pl $f
echo done $f
end

this outputs them as .mini files. 
remember to gzip up the full files

*****************

(1)make database on pfamdb2a-dev

on command line:
#echo "create database rfam_10_0;" |  mysql -h pfamdb2a -u pfam  -pmafp1  -P 3301
or just this when logged onto correct DB instance:
create database rfam_10_0

copy/dump the live database into dev:

Tends to be problems with dumping the whole database in one go so I usually resort to doing it a table at time:
copy over the relevant tables from rfamlive e.g. or do a database dump

#mysqldump --max_allowed_packet=200M -h pfamdb2a -u pfam -pmafp1 -P 3303 --opt rfamlive taxonomy | mysql -h pfamdb2a -u pfam -pmafp1 -P 3301 -C rfam_10_0

If want to try a whole db dump use this on command line:

#echo "create database rfam_10_0;" |  mysql -h pfamdb2a -u pfam  -pmafp1  -P 3301

#mysqldump --max_allowed_packet=200M -h pfamdb2a -u pfamadmin -pmafpAdmin -P 3303 --opt rfamlive | mysql -h pfamdb2a -u pfam  -pmafp1  -P 3301 -C rfam_10_0

however this usually bombs out somewhere so I go for one table at time

************

(2) get list of genomes from EBI and assign where to get them from ie Rfam or from the CON files.

output to: /nfs/pfam_nfs/rfam/rfamseq/10/Genomes_10.0/

Code for this:
#perl ./assign_genomes.pl -rel 10.0 -db rfam_10_0

memory usage on pfam doesnt go above 4%
saves copies of ebi.txt files (archaea.details.txt  bacteria.details.txt  eukaryota.details.txt  phage.details.txt  virus.details.txt) and a file 'log' with summary.

Log file says something like this:
Genomes_assigned and log file
Number of genome seq accessions 5473
Number of genome seq accessions rejected (in ensembl) 0
rfam=4258, confiles=689 unassigned=526

Note the ensembl reference is now defunct so could be removed. 
'Genomes_assigned' contains a list of each accession we need to annotate and wether to get it from Rfamseq or from the CON_ANN files. This file is needed for the make_genome_agp.pl code

************

(3) make the agp files
 
should have made the reduced con and ann files by this time-they speed this bit up (up to 10x faster...)

parse the Rfamseq set which  can be done on pfam if needed (doesnt have to be run on the farm)

#./make_genome_agp.pl -dataset rfam -release 10.0 -db rfam_10_0 >& agp.rfam.out 

Using the mini CON_ANN files from /nfs/pfam_nfs/rfam/rfamseq/CURRENT/CON_ANN
Using the Genomes_assigned file from /nfs/pfam_nfs/rfam/rfamseq/CURRENT/Genomes_10.0/
Data output to: /nfs/pfam_nfs/rfam/rfamseq/CURRENT/Genomes_10.0/genome_agp_embl100.rfam 

parse the CON files on the farm
It parses the con files by species e.g mam, mus, hum, rod, pln.  

#bsub -q normal -o /nfs/team71/pfam/jd7/RELEASE_10.0/agp.CON.out -M13000000 -R 'select[type==X86_64 && mem>13000] rusage[mem=13000]' /nfs/team71/pfam/jd7/RELEASE_10.0/make_genome_agp.pl -dataset con -release 10.0 -db rfam_10_0

log of errors/comments in:agp.CON.out
output data files like this: /nfs/pfam_nfs/rfam/rfamseq/CURRENT/Genomes_10.0/genome_agp_embl100.con.env
outputs the files for each tax div to : /nfs/pfam_nfs/rfam/rfamseq/10/Genomes_10.0

nb-this code keeps getting stuck on the last set 'rod'- easy enough to get it to run on one set at time-ended up doing this for the rod set.  Specify this in the code-line 241 and add an exit...- This should be tidied up to be an option if we want to do it this way. Ideally it should just run through all of the species. For various reasons I have had to go back and regenerat a specific set e.g. the rod or hum. so I guess options should be added...


*************

ENSEMBL:

This is the old code I have for getting the ensembl mappings from the largest fragment to the smallest they have.
In the majority of cases this is NOT an embl accession and indeed by release 10_0 we didnt bother using this code at all. However for release 9_1 we did use for 4 genomes:
Anyway here is the basic outline of what to do should it be needed:

if want to manually look at Ensembl rdb:

mysql -uanonymous -hensembldb.ensembl.org -P5306
use ensembl_compara_56;

Need to get the list of the names for each species databases for this ensembl release:
#perl ./getENSdb.p > ENS_56_dblist (list of genomes needed for the getCoordsytem code)

Need to pre-generate a lookup for the species:coordinate mapping which is different for each species
#perl ./getCoordSystem.pl -infile ./ENS_56_dblist

need to set perl5lib to
#echo $PERL5LIB
/nfs/acari/ba1/cvs_co_14Jul08/ensembl/modules:/nfs/acari/ba1/cvs_co_14Jul08//ensembl-pipeline/modules:/nfs/acari/ba1/cvs_co_14Jul08/ensembl-analysis/modules:/nfs/acari/ba1/PerlCode/bioperl-1.4:/nfs/acari/ba1/cvs_co_14Jul08/ensembl-analysis/scripts:/nfs/acari/ba1/cvs_co_14Jul08/ensembl-analysis/scripts/buildchecks/

#./runAssemblyMap.sh 
(this runs the code: assembly_mapping.pl)
This will generate the mapping file for each species:outputs a gp file for each species:
 
Then need to make an agp file from this mapping file: and load into the rdb. However we didn't do any of this for release 10.0 so all the subsequent code was not maintained to allow for ensembl ids...so I havent documented any more of it as both RDB schema and code changed. However you would just need to write a hack of the make_genome_agp.pl and the load_genome.agp.pl


However for release 10.0 we didnt end up using this using anything from Ensembl. 
For release 10.0 we wanted to use GRCh37 but couldnt get the coordinates from Ensembl. So essentially went back to the EBI llist for eukaryotes.txt and changed the accessions for the human 22 + xy in the accessions list to those for GRCh37. Note I manually curated this list: see file  'GRCh37' contains list of the accessions that were replaced. It would be good is this was automated.

Integrate these changes into the Genomes_assigned file in order to use the new accessions for human and not those assigned by EBI.

Then I just needed to remake the human.agp file using the standard code (as in  3 above)-note set the ctype in the code to 'hum' and an exit so it doesnt regenerate files of all tax divisions.- this is referred to in 3 above.

./make_genome_agp.pl -dataset con -release 10.0 -db rfam_10_0 >>& agp.CON.repeats.out


****************

(4) Load in the agp data in to the tables:
genome_entry
chromosome_build
rfam_reg_full tables.

One entry per accession into genome_entry table. Then the agp data is loaded into the chromosome_build data and hence tied to rfaseq. Finally the annotations to each genome are recorded in the rfam_reg_full data. During this process the co-ordinates of the annotation on the genome are also resolved (in rfam_reg_full table)

load the rfamseq genomes (where the genome frag is not a contig and is already in rfamseq)
./load_genome_entry.pl -release 10.0 -db rfam_10_0 -agp genome_agp_embl100.rfam >& load_genome_rfam_log
load in the contig genome data for each species:
./load_genome_entry.pl -release 10.0 -db rfam_10_0 -agp genome_agp_embl100.con.env >& load_genome_con_log

list of queries to keep track of loadings:

release rfam_10_0

QC checks-by this point these numbers should mean something to you...:

1 select min(auto_genome) from genome_entry; = 1
2 select max(auto_genome) from genome_entry; = 4179
3 select count(auto_genome) from chromosome_build;= 4179
4 select count(distinct auto_genome) from rfam_reg_full where auto_genome > 0 = 1969 annotated complete seq genomes
5 select count(auto_rfamseq) from rfam_reg_full where auto_genome > 0; = 110613 annotations on complete seq genomes
6 select count(distinct auto_rfamseq) from rfam_reg_full; = 2267754 sequences annotated	
7 select count(distinct auto_rfamseq) from rfam_reg_full where auto_genome> 0; =1969  should be the same as in 4 for rfam genomes

Con:
select max(auto_genome) from genome_entry;=4841 (3 less than before as expected)
select count(auto_genome) from chromosome_build; = 1669009
select count(distinct auto_genome) from chromosome_build = 4837  (4 missing from the total as last time...con seqs not in rfamseq )
select count(distinct auto_genome) from rfam_reg_full where auto_genome > 0;=2598   annotated genomes
select count(distinct auto_genome) from rfam_reg_full where auto_genome > 4179; = 629  annotated cons genomes
select count(auto_rfamseq) from rfam_reg_full where auto_genome > 0; = 513465 (0.5 million annotations on genomes) 
select count(distinct auto_rfamseq) from rfam_reg_full where auto_genome> 0;= 219584


*************************

(5) make load up the GFF3 files
This outputs to /lustre/pfam/rfam/Production/Rfam/RELEASES/10.0/Genomes/genome_sscons

./makeGFF3.pl -db rfam_10_0 -rel 10.0 -load

one file per EBI genome accession.
the -load option uploads the relevant gff file to genome_gff table.


****************************

(6) make the sscons files (stockholm format files) for each annotation.

-need the gff files to be made before making the sscons files as the code uses the sscons files.
this code is slow- as it takes the full seq annotation and sscons annotation and removes gaps and unused ss cons.
tend to run it in parallel for various subsets of seqs (specified by letter e.g CM for all accesions beginning with CM000663.1).

 perl ./makeFastaSS.pl -db rfam_10_0 -rel 10.0 -set CM

this code will get the list of the accession beginning with CM in the genome_gff3 dir and work through them one at a time. if the sscons file for this acc has already been made it will skip to the next one. 


***************************

(7) make the genome_summary data:
very quick-collates species data and annotation summaries for each ncbi id we have annotations on:

perl ./load_genome_summary.pl -rel 10.0 -db rfam_10_0 

tar them up for ftp site:

tar -cvf genome.gff3.tar ./genome_gff/*.gff3

tar -cvf genome.sscona.tar ./genome_sscons/*.sscons